
NET NODE STORAGE:

- basic storage functionality is file storage identified by an id/address/reference/etc. (block/index/array > key/map > path/graph > query/algorithm)
- advanced storage functionalities are abstracted over file functionality (directory, permissions, sharing, groups, data, databases, etc.)
- files (whose content can be "infinite"), must be represented by "finite/short" id
- file-id: must be chosen if lenght should be fixed, variable, block incremental
- index system: service based on a function (injective) file-id -> file (file-id is not chose by user but generated by the system)
- verifiable index system: when id = f(file)
file-id is generated/updated by the system at the end of each write process (stream close)
while writing, id theoretically changes dynamically, in practice use a temporary path and only at the end reindex

--------------------------------------------------------------------------------

INDEX SYSTEM IMPLEMENTATIONS:

- idx-hash = hash index system: /m/net/index/hash/<alg>/*
file-name = file-hash -> file (<hash-path>/file)
multiple hashes supported at same time, but if alg not specified (<alg>/<hash>) a default is used
typically cache size is big and number of items relatively small

- idx-ref = hash reference index system: /m/net/index/hash-ref/<alg>/*
file-name = file-hash -> file-ref = ref-file / hash-ref-file / hash-ref-zero-file
ref-file = <hash-path>/ref-file: internal/external index system (hash, part, node, user, http, kad, etc.) + reference-id/link
hash-ref-file = <hash-path>/ref-name/<name>: file containing only a hash (file-hash / part-index-file-hash / etc.)
hash-ref-zero-file = <hash-path>/ref-hash/<hash>: zero sized file named by the hash reference
hashes of external files are verified while streaming file and at last byte, if hash do not match, throw error before closing stream
functions to query origin of file
typically cache size is big and number of items relatively small

- idx-part = part index system: /m/net/index/hash-part/<alg>/*
file-name = part-index-file-hash -> part-files -> file
same as idx-hash, but only for *.part.json (part-index-files) files
part-index-file = *.part.json -> structure to recontruct whole file from parts (part-files)
typically cache size is average and number of items is average

- idx-mount = join other idx file under specific name: /m/net/index/mount/<name>/*
files are addressed as: <mount-name>/<original-index>
mount name must not be a path only for clarity, paths must be provided by specific interface where unreadable idx are completely hidden by a human-readable path

- idx-path = directory-path-ref index system: /m/net/index/path/*
path -> file-ref / folder
mirrors a filesystem tree where files are actually file-ref (tree on one store, files referenced on another file store)
typically cache size is small and number of items is big

- idx-path-rev = directory-path-ref index system with reverse references: /m/net/index/path-rev/*
same as idx-path, but keeps reverse indexes of file-refs
file-refs/folders can have symlinks/links???

- idx-path-hash = folder-path-hash / file-path-hash: /m/net/index/path-hash/<alg>/*
path-hash -> file-hash and/or folder -> file / folder query result
hidden paths: those paths unreachable from browsing folders, only from full path known a priori
NB hidden paths means actually that path is not a fully connected graph eg path1/path2 may not exist while path1/path2/path3 exists
paths are variant: same path can be a file AND a folder
same hash-alg for index and file reference
typically cache size is small and number of items is big

- idx-table = indexed-tables index system: /m/net/index/table/*
query -> row (json or xml)

- idx-object = indexed-tables index system: /m/net/index/object/*
query -> object (json or xml)



- store-hash:
support of single hash alg, multiple support is achieved with a wrapper
on creation if declared hash is not provided then temporary id/fake-hash (date-time-random)
on close do nothing
on seal calc hash, rename by it and return it
specific implementations may allow delete, or edit-rehash, others may not
store-hash/
  sealed/<hash-path>/file
  unsealed/<tmp-id-path>/file
local store allows only files completely stored locally -> <hash-path>/file
universal store permits references to external files (strong hash is extremely advised) -> <hash-path>/reference ("file" is not present)
reference file: contains type of external storage and info/data/link/reference to get it (eg type=http, data=link)
if "reference" is a zero byte file it only guarantees existence, but search must be done on other nodes, other search engines, or in real life
NB if origin provided in ref-file is not available, then a search can be performed on the net (other nodes) with the guarantee of strong hash
NB universal may not be suitable for some legal stores

*.jdf = json data folder/format:
json-data + ref-protocol -> ref-strings: "ref-id=<field-name>": "ref@<hash>"
references to other files (even other jdf files) guarantee hierarchical identification and integrity
on create/modify/save jdf accepts only "Obj" or json equivalent structures, it fully walks to find references
implementation defines if references must be local or can be universal/external
it should generalize type for document ("type" string as root element) and subtypes for each element (name = "@<type-name>:<field-name>" -> string, number, object, etc.)

store-sig = store-signature:
table <sig, agent, file>

- idx-part = part index system: /m/net/index/hash-part/<alg>/*
separation from idx-hash only for ease managing sharing size and redundancy, but technically they are the same only content type changes
on creation/edit big files are splitted according to a split policy in more files whose hash is saved as hash-array into a part.json file indexed with its own hash
partitioning can be applied recursively (either using part.json files recursively, or use only one big part.json with all part hierarchy)
any part can be of arbitrary size and partitioning can be even manual
simple policy 1: divide in parts of a predefined size
simple policy 2: divide in N parts until parts are smaller than a predefined size
simple policy 3: use any other policy, if resulting part.json file is bigger than a predefined size then apply partitioning on part.json file
for anonymity parts should be configured to be always of the same size and padding to that size (pol-1 -> pad last file, pol-2 -> pad all files)
NB part-hash can substitute file-hash to identify the file and to guarantee its integrity (for each specific file partitioning, block hash is unique)
text/json files can become big, in the future more formats can be supported eg a universal binary object format

- idx-path = directory-path-ref index system: /m/net/index/path/*
NB unverifiable index system by nature NOT based on idx-hash (but links to it), but on direct filesystem index representation
allows direct access to files/dirs by path
allows browsing of dirs by path
allows link to files implicitly
exposure of full paths and file names may affect privacy
does not allow folder link unless underlying os filesystem supports it -> remove feature by desing to prevent incompatibilities
reverse links (only for files): <idx-path-root>/reverse/<file-hash-path>/ -> list of paths where the file is linked

NB idx-path and idx-part represent the node awareness of the net (links to local index cache or other node cache)
while idx-hash represent the local node effective storage

- idx-file-path-hash = file-path-hash: /m/net/index/path-hash/<alg>/*
NB unverifiable index system by nature NOT based on idx-hash (but links to it), but on indirect filesystem index representation
allows direct access to files/dirs by path
does not allow browsing of dirs by path
allows link to files implicitly
path privacy guarranteed at maximum level (adding permission and encryption guarrantees full file privacy/security)
reverse links (only for files): <idx-path-root>/reverse/<file-hash-path>/ -> list of paths where the file is linked
NB a path system can be restricted to root and it will be a tag system, or with some helper api use the full paths to achieve and extensive tag 
classification and put easily files into many folder/tags + browsing filtering (eg merge and/or group many folders -> union, intersect, etc.)
NB keep user, session, time and any other info useful for later searches and filtering

- idx-path-hash = directory-path-hash: /m/net/index/path-hash/<alg>/*
extends idx-file-path-hash
file-path-hash -> ref-file / ref-folder ->
<path-hash>/file = ref-file
<path-hash>/path/ = ref-folder
    folder/<zero-bytes-files with names of sub-folders>
    file/<zero-bytes-files with names of files>
reverse/
  folder/
    <path-hashes> / zero files named by hashes of parents
  file/
    <file-hashes> / zero files named by hashes of parents
NB by design: declared content of ref-folder may not be present (missing refs (unwanted feature)) or may be present other (hidden) files/folders not declared (wanted feature)
to prevent missing refs, existence check must be done on additions to folder and on file/folder delete also parent folder reference must be removed
NB file ref is not present in ref-folder because it would be a duplicate and also this way allows more detailed security policies of folder vs files
NB ref-folder allows filesystem browsing
allows link to folders implicitly

- idx-table = indexed-tables index system: /m/net/index/table/*
sealed/<table>/<key-hash>/
  file: key
  data: json of full row (pk included)
indexes=reverse/<table>/
  <field>/<value-hash>/zero files named by hashes of parents
NB for small amount of data this structure can be help into a json file and stored into a sealed store, or sss can be extended as data store
to use the full file structure inside an element

- idx-data:
some dirs or files are treated differently and offer specific api to access manipulate data inside (json, xml, csv, indexed db table)
each format should allow inside references (foreign keys) to external objects (file, dir, data with path inside data-file)















-idx-query = data query index system: /m/net/index/query/*
same as idx-path + idx-hash, but performs queries into specific file formats (json, csv, xml, etc.)
based on idx-path, some dirs have extensions (eg mydir/mydata.json/, mydir/mydbtable.table/, etc.) inside multiple files (eg ddl, table indexes, ext foreign keys tables, etc.)
data files max sizes of 100MB
data must be partitioned to fit into max part-size, small enough to ease updates, big enough to limit traffic

-idx-message = message index system: /m/net/index/message/*
same as idx-path + idx-hash, but stores messages
must be as fast as possible
chat: direct connection between nodes or few hops, client server model for chat rooms, group model for forums, broadcast model for feeds/podcasts/streams/etc.

- net = os command that, if needed, delegate command execution (https, raw socket, etc.) to the configured node (default is localhost)
eg: net path test/file -> will look for /m/net/index/path/test/file and download to /m/net/file/path/test/file
/m/net fuse/kernel filesystem that represent a view of the path index using the net command
on some file operation linked file is downloaded/cached and used for actual operation
on other file operations other indexes are affected (permissions, attributes, etc.)
some files can represent data or another fs and will integrate it transparently (eg a json is showed as a nested fs and not as a file)
m-net-fs params for caching files etc. are not related to idx-hash cache params, but by default idx-hash adds those files to index

os shell or file manager cannot see effectively all things (eg a forum can be represented as filesystem, but fileman is not the best gui to browse)
a net file can represent anything (depending of the index it comes from): a file, json data, table data, a forum, command, service, etc.
the net fs must support links and possibly even with different permissions (eg the same file both private and encrypted and public and unencrypted)
NB path index supports links by its core nature

- permissions:
/m/net can be administered with os permissions, but net permissions will enforce more restrictive permissions
generally os users are not integrated with net users (except for m-os)
net permissions work through encription and keys, every os permission nowadays is fake security, only encription works
m-os kernel detect net files operation to extend filesystems api to give user feedback when opening requires download, or decription, etc.
for starters such operations suffice to be present in the "m file manager" or "net" command



every index system will take great advantage to a standardization of file encoding/packing/tagging (similar to an ebedded mime specification)
NB think about a file encoding that encapsulates file name or full path into whole hash and shares that instead of plain file (not useful for global dir)
more generally any set of property/tag can be encapsulated (eg original author, title, description, format, language, releaser, etc.)
NB link files are more effective into idx-path, but they can also be into idx-hash as regular files (client will interpret them as link)
any user can add any file to its index systems, but net decides which to upload and make redundant
blocks sizes always multiple of 10 (1KB, 10KB, 100KB, 1MB, 10MB, 100MB, 1GB, 10GB, 100GB, 1TB, etc.)
NB the same file-segment can be a part of a bigger file in a node (releaser or downloader), or a whole file in another node (cacher)
NB for complete anonimity node can share/upload files into cache directly so that everything is managed by net and original file can be destroyed

- node/user index system: /m/net/index/node/<node-id>/<index-system>/* /m/net/index/user/<user-id>/<index-system>/*
served directly from node/user when online/user-logged-on-its-node
node/user may ask the net for full/partial net serving (requires credits)
full index or file index must be signed by node/user
node/user privacy is obviously absent
node/user can use itself one or many index systems for its files or services (NB local paths can also refer to external resources)

NB difference between net index and node index is that node index respond only for what that node stores, net index may respon directly if request can be accomplished 
with node storage or interact with other nodes, but all happens transparently to the requester -> for privacy node indexes should be denied for direct access

- access control must be applied both at file level and at index system for upload/download for maximum protection

--------------------------------------------------------------------------------



obscure with simmetric encryption at block level to prevent damaged blocks to unencrypt whole file, do it at whole file to protect it against unauthorized access

- file storage must be accepted by the network (each node)
criteria can be various
criteria for index files should be different from other files (index systems are most important)

- possible criteria:
unique position but everyone can give arbitrary content -> client can use different policies: 
trust everything / trust any signed / trust specific signatures
replace local with newest
merge local with any remote
keep local

- policy: criteria that decide if files are accepted and stored into the network or served to user/node

unsigned index files should be avoided by default because spam and flood are guarranteed
but freedom and anonymity should be guarranteed
good compromise seem to be to accept anonymous or rated signatures that can always be blacklisted
whitelist should be preferred because blacklist can be easily flooded
a soft whitelist can be to allow signatures with rating higher than some level, acquiring rating points involves effort that may solve issues
so the problem is shifted to: how the network should accept anonymous signatures and rate them
possible workflow: anyone can generate pub+pri keys, rating can be bought or given by many other nodes/users by proof of some expensive work
problem how to give rating by keeping privacy of giver and prevent abuse or mutual agreements
a possibility is calculate hashes of huge file blocks, because that implies that somehow it has served those files and thus the net



data compression with global ai determining dictionary based on most common fragments -> smaller index
data formats for streaming must be progressive (as progressive jpeg) to minimize quality loss on data/stream loss



verifyable-file: hash + file (where file can be encoded, even recursively)
untouched: file = original file
signed: file = pub-key + append sym-key + file-hash encoded with pri-key + append of original file encoded with sym-key
obscured: file = sym-key + append of original file encoded with sym-key
protected: file = sym-key encoded with some key + append of original file encoded with sym-key
private: file = sym-key encoded with user pub-key + append of original file encoded with sym-key



query inside a file is easy

for other complex data types, they are stored in files with same methodology (object, tables, geographic, etc.)
query inside each type require a specific interface that should be the same for all types (tbd)

NB all this is highly traceable
possible solution:
at first upload each block is encrypted with different keys, wich are kept in its block list file...recurse...
of course there must be an alg to decode, but this way
each block is uninspectable, unless all block hashes are together (blockchain of dht)
this way is easy to apply a master password to a file and then change it (only master index must be rewritten) 
useful for group shares (NB issue: change propagation)
idea: same rehashed and new dht on each node that keeps redundancy (same block is different on each node), 
problem is each block must be retrived completely by same node
...bad idea, does not add significant value, but constrints are too risky

incremental versioning by saving only blocks changed and make an xdelta of the block

fh = file hash
file = ef = encryted file using fh as symmmetric key
start recursion by dividing into ordered blocks
hi = hash index = file containing ordered list of blocks hashes
efbi = block number i of ef
efbih = hash of efbi block
effh = file containing ordered efbih
recurse using file = effh
at the last step effh-name = fh

NB every info/file is compressed: text is gzipped, audio is flac, image and video ??? in any case compression must be lossless unless original is already a lossy format

NB every file is obscured: obscure a file means that it is impossible to extract partial content unless all file blocks are available -> blockchain of file blocks
blockchain of file blocks: file reference gives the first sym-key to dec first block at end of wich there is sym-key for next block, etc. this prevent efficient file edit
NB next key must be encoded together with whole block, otherwise i can download only key from previous block
NB obscure file and data is a counter measure to prevent selective (NB general attacks are nearly impossible) attacks to the network (eg destroy some datasets)
find other counter measures against selective attacks
