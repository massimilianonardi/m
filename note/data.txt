
- even the most atomic data is in a specific format/encoding

- data is read from server and streamed as format/encoding requested, client receives stream and parses as format/encoding requested. 

- servlets: 
  simple: get params, path, etc. init proper handler, get start response and print, loop print stream response, print response end from handler. 
  advanced: 
    auth filter: 
      get session logged user and associated config and policies
      parse url servletpath + pathinfo
      get request size and approve against global policies
      get request parameter params and parse as json
      use all the above to init an ActionRequest object
      validate ar-obj against policies and return updated ar-obj with status detail 
      status can be: approved, partially approved with properly modified params, rejejcted, etc.
      dispatch properly to action/error handler 
    specific servlet: 
      extracts specific parameters from url or takes some actions depending on parameters (make post params as fallback of params props for hand made url requests) 
      determines eventual web helper classes to invoke for specific situations

- data validation based on json data description language (json-ddl)
    json-data: <type, meta, data>
    json-ddl:
    type_name
    {
      type: undefined/string/number/object/array
      // if string or number
      validator: TODO -> superseed constrains
      // if object
      mandatory: {prop1: predefined type_name or inline anonymous type definition, prop2: type_name2, ...}
      permitted: ... // if undefined then no facoltative properties, if empty then everything but forbidden is allowed
      forbidden: ...
      // if array
      min: // minimum number of elements (-1 for any)
      max: ...
      mandatory: {index1: type_name1, index2: type_name2, ...} // mandatory structures at specific indexes
      permitted: [type_name1, type_name2, ...] // permitted structures for any not mandatory array element
      forbidden: ...
    }
    field validation is easy, but how to perform global validation?
    generate sql ddl for specific vendor (postgres, oracle, etc.) only with simple constraints, all constraints are performed at application level (or generate triggers?)

data undo in multi-user environment is not trivial to manage

data enter/exit/move events are part of data:
functionality must have a switch because can be a performance hit
a general purpose detection function is provided, but a custom one can be provided, or a set of predefined functions can be provided as for translation
data enter/exit/move events are generated inside the data(value) property setter function
NB this functionality means monitoring a 2-state transition



ATTRIBUTE SYSTEM:
-----------------

standard table concept: objects with fixed recordset grouped inside the same table

grouping should not imply same recordset -> attribute system

attribute system: one table of attribute list, one table to associate objects with attributes and give attribute value (as string for generality)

attributes can then be grouped with the maximum flexibility

attribute grouping is like old table definition

attributes are then the old colmns of every table into one unique list

is it possible to generate views to obtain old tables? yes: query where attr1 join query attr2 etc

attribute system is necessary when there are one to many relationships or not omogeneus recordset, when one to one is optional because old table can be used, but using it allows maximum generalization

attributes can be typed by adding a type column into the attribute list table and having as many association tables as many types are allowed
