INPUT OUTPUT

attualmente:
- input:
  constructor -> init + start
  start/stop register/unregister connected devices and start/stop thread processing loop
  get: returns currently connected devices
  set: registers/unregisters list of devices specified by params
  create: create a specific filtered queue of events -> returns queue pointer
  destroy: destroy previously created filtered queue of events
  read: (blocking) returns event on top of the fifo queue

--------------------------------------------------------------------------------

- anche un device di i/o come un touchscreen, è in realtà due cose: lcd di output + vetro touch => non esistono device dove in e out siano inscindibili
  quindi: iodev -> driver -> <in, out> / <in> / <out> => ui si interfaccia con in/out non con iodev
- è necessario standardizzare gli i/o (es. tasti keyboard di tutte le lingue; rendering tramite window manager, opengl, o directx;
  output finestre 2D, oggetti e finestre 3D; input 1D, 2D, continuo, discreto, ecc.)
- input-device: rende disponibile l'input proveniente da una determinata classe di devices, standardizzandolo (es. one-value/multi-value -> button/axis, absolute/relative, ecc.)
- input: rende disponibili tutti gli input possibili tramite i vari input-device secondo policy anche molto complesse ed offrendo filtering e remapping molto avanzati
- loader policy deve consentire l'accesso ai vari input-device solo ad input (o a particolari eccezioni)
- le varie ui usano input eventualmente chiedendogli un filtraggio generico dinamico, ma sono loro che devono operare il filtraggio specifico (es. window under mouse coords)
- input-device standard:
  id -> device unique identifier
  type -> keyboard, mouse, audio card, etc.
  val_type -> button_down=1, button_up=2, absolute_value=3, relative_value=4, absolute_normalized_value=5, relative_normalized_value=6
  val -> <button_id> OR <key_id> OR <x1,x2,x3,...> (NB key_id is the raw scancode, no lang map, no special keys interpretation...shift, ctrl, etc. are just any key)
- input standard: =input-device
- input filtered: =input-device
  id -> filter_id -> registered virtual device id (so real devices and filters are indistiguishable)
  type -> can be a device type or a new registered type for this filter as a virtual device (keyboard, "keyboard_translated", mouse, "mouse_keyboard", audio card, etc.)
  val_type -> same as devices
  val -> same as devices: <x1> ... <x1, ... ,xn> (xi: double)
  NB es. filtro di tipo mouse+keyb t.c. <x1> può essere l_button_up, vk_A_down, fmode_on, etc. cioè tutti i tasti del mouse e della tastiera sono mappati insieme
  NB es. filtro di tipo mouse t.c. per ogni device con almeno due val continui, vengono presi i primi due assi
  NB es. filtro di tipo keyboard da ogni device di tipo keyboard reinterpreta ogni tasto in base al lang e tasti speciali shift, ctrl, etc.
  input possiede nella sua configurazione dei filtri precostituiti utilizzabili (da ui mouse e tastiera) con lazy start (se nessuno li richiede non partono)...
  NB i filtri come virtual device comportano che ad esempio il translate della keyboard viene fatto una volta sola anche se molti utilizzano il filtro...
  NB un filtro può generare un id fake per simulare uno specifico device...comunque in generale i client non devono guardare l'id, ma alcuni si (es. più mouse -> più puntatori)
  NB se per i filtri si usa un lazy filtering, allora ho massima efficienza perchè filtro solo se qualcuno legge effettivamente quell'input (da verificarne l'utilità)
  i filtri possono essere rimpiazzati in real time in modo trasparente agli utilizzatori (es. rimpiazzo il filtro mouse usato da gui con uno che utilizza la scheda audio come mouse)
  la creazione dei filtri avviene mediante classi specializzate molto efficienti ed una o poche classi general purpose che devono poter consentire qualunque rielaborazione
  in generale le ui devono venir costruite su filtered input per generalità...NB le policy di input generalmente devono impedire il raw input
- modello stream per le sequence di input:
  uno stream è una seq t.c. 
  stream(0) = data packet
  stream(1) = seq-link to next stream packet
  stream(2) = seq-link to prev stream packet (only for bidirectional streams)
- modello di acquisizione input degli input-device:
  ogni in-dev restituisce il suo stream di eventi a input tramite get
  ogni in-dev gestisce lo stream buffer, quindi lo tronca quando necessario eventualmente anche se non tutti hanno letto gli eventi più vecchi (usando seq-link evito data races forse)
  input decide come elaborare i vari stream (priorità, prevent device flood, ecc.)
  input, su richiesta dei client, genera stream di virtual devices prestandardizzati, o creati dai client (lazy start?)
  i client di input si registrano per determinati eventi sulla base di <id, type, val_type> (compresi eventi virtuali) avendo di ritorno lo stream della sottoscrizione
  input processa tutte le code delle device reali e virtuali linkando ogni evento ai relativi stream dei sottoscrittori, a questo punto l'evento viene rimosso dalla coda di in-dev
  contestualmente alla rimozione, viene notificato in-dev che la coda è diminuita, quest'ultimo ha quindi sotto controllo la dim del buffer
  con questo meccanismo, sia copiando che linkando le seq, l'effettiva distruzione avviene senza data races
  chi tiene traccia invece degli stream dei singoli sottoscrittori? -> il sottoscrittore! ...semplice...ma non mi piace...inoltre...
  ...inoltre, input è un srv unico, quindi i vari client sono connessi almeno in shmem, quindi se faccio un input-client posso ottimizzare la shmem e gestire la dim dello stream

- in-dev -> stream-in-ex (si-ex), input -> stream-in-out-multi (sio-mu)
- in-dev -> stream-in-multi (fast arch = speed ex), input -> stream-in-out-multi (fast arch)
- input acq (fast stream model):
  i client di input si registrano per determinati eventi sulla base di <id, type, val_type> (compresi eventi virtuali)
  input inizializza i vari in-dev reali/virtuali direttamente necessari per le sottoscrizioni ricevute
  gli in-dev virtuali (stream-io) si registrano come client sugli in-dev da cui dipendono 
  NB loader deve restituire ad in-dev direttamente il ptr di input perchè deve riconoscere che fanno parte dello stesso processo
  acq loop (simple, avoid flood, slow for may in-dev): for each in-dev read, if!=empty, dispatch (loop never waits)
  acq loop (multithreaded, synch, slow for few in-dev): for each in-dev instantiation, new dedicated acq thread (while available, read, write in synch to global queue)
  acq loop (no multithreaded, no synch, fastest, no queue man, flood prone): for each in-dev instantiation, call set, write called by in-dev dispatch event based on subscriptions
  l'ultimo acq loop, è quello perfetto, la queue management la può fare un thread separato usando counter per ogni id, set(0) sugli s3m-in flooding, ecc.

  se invece faccio input-filter a parte posso massimizzare le performance, ma limito notevolmente l'architettura (input esclusivi di uno solo), se tramite loader la espando...
  vediamo...un srv (es. ui) carica input locale, chiede un device id, se reale allora ritorna in-dev-ex, se virt allora ritorna in-filt-ex su uno o più in-dev-ex
  tramite loader potri far si che input locale ui carichi input srv, ma la cosa non è gestibile a runtime, solo a sys start...NO!

  migliore: in-dev usa come buffer una shmem circolare, input legge in loop il buffer (NON bloccante), se ritorna -1 (no input), richiama wait di in-dev 
  (più veloce, blocco solo qundo non c'è input)...NB da rivedere...
  input passa ad ogni in-dev il ptr a se stesso, ogni in-dev on new input, richiamano input.write(params) specificando il loro device id che scrive il nuovo input nella coda dedicata. 
  NB così un trusted in-dev può simulare l'input fisico di qualsiasi altra device...al momento mi piace, ma se come design non dovesse andare bene allora input deve creare 
  tanti altri oggetti derivati da service che passa ad ogni in-dev, per ciascuno di questi oggetti la coda è determinata dal costruttore e write ignora l'id passato...
  NB posso implementare che il design da usare per ogni in-dev (o globale), sia configurabile che mi piace ancora di più...
  NB per essere thread safe, devo far si che siano solo gli in-dev a manipolare le loro code, quindi con write aggiungono, ma come rimuovono? e input come sa quale input è il prox?
  se uso un buffer circolare è tutto perfetto (verificare) tranne il fatto che se un client è più lento di in-dev, subisce dei jitter...ovvero gli tronca la coda e periodicamente 
  gli va a sovrascrivere l'input mentre lo sta leggendo (molto pericoloso), se invece uso delle liste bi-infinite, non ho più questi problemi, anzi quando write tronca la coda 
  cresciuta troppo la distruzione dei vecchi input avviene solo quando tutti i client che lo hanno letto, hanno finito con esso in virtù del link tra sequenze come sh-ptr.
  altra ipotesi: in-dev tiene e gestisce la sua queue circolare aggiornando il link alla testa (= l'ultimo input arrivato), input tramite get prende il link, basta.
- input ed output come stream in modo che posso connettere le cose più impensabili (rete, video, audio, hdmi, hd, dvd, ecc.)

comandi di output specifici per alcuni output:
- render_image: può anche essere mappato come suono anche se non è pratico
- render_sound: può anche essere mappato come immagine anche se non è pratico
- render_video: può splittato e mappato su due device diversi (stereo e monitor) o intero (tv)
- render_3D_video: come sopra (3D->2D), o può essere mandato ad un generatore di ologrammi (3D->3D)
NB in generale per l'output andrebbero considerati i 5 sensi umani, poichè essendo l'utente un umano 
   i device out servono proprio per dare feedback all'utente quindi possono essere implementati anche 
   render_taste e render_smell...NB per il tatto c'è già il 3D al quale vanno aggiunte tutte le variabili 
   tattili non grafiche come ad esempio temperatura, umidità, vento, ecc.
NB andrebbero considerate anche pressione, gravità ecc. e qualunque cosa il corpo umano possa percepire...
NB viceversa input mappa i 5 sensi e qualunque cosa nell'universo in text/number
NB i comandi render_text/number/image/sound/video/3D vanno usati solo quando rappresentano i dati per il resto si 
usano le properties cioè si separano i dati dalla presentazione (skin). la differenziazione deriva dal fatto che 
le skin sono date a priori e fanno parte dell'app (anche se se ne possono scaricare altre, ecc.) mentre i 
dati derivano dai srv utilizzati. infatti il compito degli ui_elem è proprio quello di splittare output complessi 
derivanti dai srv e mapparli nei 5 sensi, cioè ui è la mappatura: user_interface = sequence -> human_senses
cioè la ui contestualizza i dati astratti conferendogli una particolare semantica
NB per i text/number va considerato che sono dati astratti che possono essere mappati teoricamente in ognuno dei 
5 sensi, quindi più i dati hanno senso come text/number e meglio è perchè mi lasciano libertà di scelta su 
come rappresentarli, quando invece voglio mappare text/number in uno dei 5 sensi per una migliore percezione 
(come ad es una percentuale in una barra di completamento, istogramma ecc.), questo va contemplato nelle 
properties proprio perchè mantenendo questo disaccoppiamento totale tra dati e presentazione, io comunque ho 
la massima portabilità dell'app su ogni output (a meno dei dati che per loro natura non sono text/number), 
scrivere le app è estremamente semplice e non richiede di scrivere la ui perchè viene automatica dalla 
logica della app e poi possono essere definite varie configurazioni di output che perfezionano l'esperienza 
di interazione (ad es usando audio/video come out, creo una skin multimediale che trasforma una semplice gui 
con solo controlli e bottoni con testo in un'app strabiliante)

NB si potrebbe creare un input filter ui che mappa gli input in:
- execute: esegue il comando correntemente preparato e parametrizzato con le var interne del ui_elem
- select: seleziona il ui_elem
- deselect: deseleziona il ui_elem
- clear_selection:
- invert_selection:
- edit:
- clear:
- save_edit:
- cancel_edit:
- focus:
- highlight:
- create:
- destroy:
- show:
- hide:
- axis_??: coordinata percentuale (definire i valori standard...)
- character_??: "carattere" che può essere ascii, unicode ecc.
- value: numero
NB sono solo un esempio di tutti quelli che mi vengono in mente, le idee più chiare me le posso fare solo poi

NB esempi per ribadire che non si perde in flessibilità o potenzialità:
- un image viewer come xnview che cacha l'immagine successiva e che renderizza progressivamente in 
alta qualità è fattibile così: per la cache renderizzo l'immagine successiva in un controllo 
doppione settato come hidden, poi quando vado avanti swappo la visibilità dei due controlli e 
sull'altro cacho; per la progressiva hq, è analogo in uno ingrandisco fast e sull'altro dopo un timer 
renderizzo hq...NB qui emerge il tema del timing/sincronizzazione/real-time/ecc. che deve essere gestito 
dalla user_interface o dai srv sottostanti? ...pensare!!!
- altro esempio è un player video: posso mandare i frames decodificati dal srv, oppure mando lo stream 
h264 al renderer il quale a sua volta lo manda alla scheda grafica per la decodifica hardware...
anche qui ci sono due controlli (e due output renderer) distinti e qui la logica del disaccoppiamento 
comincia a venire un po' meno perchè la configurazione di decoding nel secondo caso sta nel renderer 
e non nel srv player che ora fa solo da dispacciatore dello stream preso dal file, oppure ancora posso 
fornire al renderer l'id di connessione al srv di storage ed il renderer prende lo stream da solo...
insomma l'accesso alle funzionalità o accelerazioni hardware avanzate creano problemi in questo contesto, 
devo solo assicurarmi di non precludermi la possibilità di utilizzarle pur mantenendo un alto (se non totale) 
disaccoppiamento

NB il concetto di fondo è che ogni cosa può essere un input od un output che di solito vengono utilizzati dai 
vari srv nei loro formati standardizzati...però ogni input/output generico può essere collegato ad una ui a 
patto di avere un opportuno srv di mappatura che converta input/output da/per comandi ui (render, select, 
ecc.)

params sono cose abbastanza fisse, possono anche avere struttura variabile, ma fondamentalmente 
sono "un insieme finito" e mi serve unicamente per configurare il srv e vanno inviati una sola 
volta, mentre l'input è una cosa estremamente variabile, "non prevedibile", continua e potenzialmente 
infinita, cioè uno "stream" e rappresentano concettualmente "dati"...
quindi:
- params: limited-one-time-data, determinano come elaborare l'input ai params non corrisponde un output
- input/output: unlimited-continous-streaming-data, vengono elaborati (secondo i params) per produrre un output
cioè out=f(in) e f=g(params), con f=stream_function e g=point_function

differenza tra funzione e stream-processor è che per le funzioni c'è una corrispondenza sincrona tra 
input ed output, mentre per gli stream io fornisco input asincronamente e poi asincronamente e se 
voglio prendo gli output...NB se serve sincronia per gli stream questa deve essere contemplata 
all'interno dello stream, oppure previsto da timers nello stream processor (con almeno un delay 
tra in e out), ma in ogni caso non c'è la corrispondenza come nella chiamata di funzioni.

lo user input viene tradotto dalla ui in uno input stream di comandi per uno specifico srv.

riflessioni:
- se l'input passato e l'output associato sono scorrelati da tutti gli altri in ed out allora 
il modello da utilizzare è la chiamata di funzione
- se l'input passato è un pezzo di un input più grande e l'output pure viene fornito a pezzi e 
l'out complessivo dipende da tutto l'in complessivo (es. codifica video a doppia passata) allora 
il modello da utilizzare è quello delle streamed read/write indipendenti
- il vero problema è che uno stream processor proprio per sua natura implica un buffering di in ed 
out e quindi la gestione di tali buffer che devono garantire (entro certi limiti) la non perdita 
di pacchetti in o out, il buffering è necessario perchè in una catena di stream processors, il più 
lento non è sempre lo stesso ma è variabile a causa degli input istantanei che possono richiedere 
più o meno potenza di calcolo (NB la velocità di una catena è data dal processore più lento!), 
quindi se non ci fosse buffering tutti i processor starebbero sempre in attesa del più lento, 
mentre col buffering hanno sempre dati da processare...NB il tutto va considerato in "clouding", 
cioè i processors possono stare su pc distribuiti in rete, o sullo stesso pc ma diversi core, ecc.
- io vorrei che il buffering non fosse gestito dallo specifico srv, ma da backends messi prima e 
dopo, ma non sono sicuro sia fattibile...o almeno è facile bufferizzare l'input dall'esterno, 
ma l'output? ...dovrei prevedere un buffer veloce e il processor dovrebbe bloccarsi se c'è un 
pacchetto in out non ancora preso...forse così regge...
- in ogni caso il srv, anche nel caso "funzione", ha al suo interno "molta" sincronizzazione 
(semafori, wait, ecc.) che per sua natura è "pericolosa"...l'alternativa implica la comunicazione 
bidirezionale e quindi un'interfaccia ulteriore che deve implementare il chiamante, oltre al 
puntatore che va passato al srv o al suo stub e gestito da lui in sua vece...tutto ciò implica 
però anche che l'affidabilità del srv dipende anche dal suo chiamante...pessima cosa! ...e poi 
almeno le read andrebbero sincronizzate, per cui mi conviene usare il modello unidirezionale 
sincronizzato e progettare bene la classe base dei srv con tutta la sincronizzazione al suo 
interno...

- stream_in: accetta i pacchetti dello stream in ingresso da processare
- stream_out: ritorna i pacchetti dello stream in uscita processato
