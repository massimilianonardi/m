loader è un srv come gli altri tranne per il fatto che è l'unico che può interfacciarsi interamente 
con il os che l'ha lanciato e quindi l'unico che può lanciare altri processi.

anzi no, anche altri srv di sistema sono ad accesso full come loader (storage, config, log, etc.)
per ciascuno di questi si crea un exe specifico e con un md5 diverso e con nome diverso, in modo 
che tramite os (linux, mac, windows) posso dare a questi i diritti necessari e 
negare tutto a "client.exe" che genera tutti i srv "normali"

gli altri srv possono caricare solo le lib di sunaptos e nient'altro -> nb l'uso della rete è implicitamente 
concesso (purtroppo) perchè è necessaria a "client.exe" (che ha lanciato srv) per fornire la ipc

kernelloader (o remoteloader) al suo avvio lancia tutti i srv a lui funzionali come config, storage, ecc. 
poi lancia bootloader. in particolare config è importante perchè dice le regole con le quali decidere se 
i nuovi srv devono essere servizi o libs ad es. config deve essere un servizio, storage "non è necessario"...

TODO: pensare ed implementare l'architettura a supporto dei servizi in senso stretto, 
la gestione delle eccezioni ed errori attraverso le chiamate tra srv sia via ipc che tramite chiamata diretta

forse per implementare i servizi potrebbe bastare (o comunque può essere il primo passo) fare sì che 
per una stessa istanza di un srv vengano istanziati diversi canali ipc per ogni richiedente e poi è il 
particolare srv che gestisce le cose come un servizio...poi magari questo comportamento viene pensato come 
formalizzarlo ed implementarlo nell'architettura

ogni metodo accetta un solo parametro (tramite puntatore) e ritorna un solo parametro (tramite puntatore) di 
tipo "Data" (finora) ma secondo me è meglio rinominalro "Stream" (o "Grid") e definirlo come interfaccia e non classe. 
così facendo separo il problema di impacchettare/spacchettare i dati quando devono usati al di fuori del 
processo, mentre all'interno del processo mantengo il massimo dell'efficenza (con solo l'appesantimento di un 
dynamic_cast) passando puntatori che non vengono serializzati, poichè la de/serializzazione viene effettuata 
invisibilmente solo all'interno dei wrappers cli/srv degli objs.
il "DataTree" che è la cosa difficile e che ancora devo definire, dovrà essere la struttura dati "perfetta" 
che implementerà "Stream" così come ogni suo sottoclasse...tale struttura deve essere pensata considerando: 
- un bel nome
- un'implementazione che massimizzi l'efficenza della de/serializzazione
- un'implementazione che massimizzi l'efficenza d'uso corrente
- un'implementazione che tenga conto dei possibili problemi di allocazione di memoria 
  (segmentazione, out of memory, ecc.)
- un'implementazione che ottimizzi il compromesso dynamic-typing-exceptions/compile-time-check 
  (probabilmente già trovato con l'utilizzo di dynamic_cast e l'interfaccia Stream come classe base di dati)
- un'implementazione che permetta l'utilizzo di sottoinsiemi aggregati di una struttura più grande, mantenendo 
  al suo interno comunque l'indirizzo/riferimento/path all'interno della struttura madre
- un'implementazione che possibilmente permetta agevolmente il calcolo distribuito 
  (cloud/grid-computing) facendo attenzione alla ricorsività intrinseca dal grafo connesso/ciclico (media priorità)
- un'implementazione che possibilmente permetta agevolmente il calcolo parallelo (bassa priorità)
- un'implementazione che possibilmente permetta agevolmente il calcolo real-time (bassa priorità)
- un'implementazione che possibilmente agevoli la persistenza (memorizzazione in uno "storage" persistente)

le esigenze della serializzazione finalizzata all'ipc sono: 
- l'operazione di riempimento (creazione/riassegnazione) di un oggetto deve essere completata affinchè l'oggetto 
  sia valido...in futuro si potrebbe anche pensare che l'interruzione generi comunque un oggetto validato, anche 
  se troncato (comunque generando l'exception)
- la trasmissione può avvenire in pacchetti di qualsiasi dimensione sia minore che maggiore della lunghezza dell'obj
- supporto alla write protection (con una chiave)
- supporto alla read protection (con una chiave)
- supporto all'accesso random (specificando un puntatore relativo)
- supporto all'accesso sequenziale (tracciando internamente un puntatore relativo)
- supporto all'accesso ad un numero variabile di bytes restituendo il numero di bytes effettivamente letti/scritti
- supporto al monitoraggio eof/bof (anzi eos/bos)
- supporto all'accesso dichiaratamente singolo o multiplo (ad es. posso solo leggere sequenzialmente una volta)

per il momento lascio la classe Data, ma la ristrutturo mentre penso a tutto quanto sopra e comincio a ripensare 
a come cambiare ipcs e ipcc che sono coloro che de/serializzano per capire come cambiare Data/Stream:
- creo l'interfaccia Stream
- a Data gli faccio implementare l'interfaccia stream
- sistemo ipcs ipcc in modo che utilizzino i metodi dell'interfaccia stream

gli oggetti data (ed ogni altro tipo per cui serva) vengono creati non con un "new" ma con due metodi: 
uno "persistent" che fa la stessa cosa di new ed uno "scoped" che viene memorizzato internamente in modo che 
quando viene chiamato il distruttore, questo fa il "delete" su tutti i puntatori scoped...in pratica fa una 
semplice "garbage collection" e cerca di evitare i più comuni casini fatti con i puntatori gestiti a mano

data ha una componente di definizione struttura "dstruct" (hashata per fare i check) ed una componente di buffer 
virtuale "vbuffer" che gestisce trasparentemente l'allocazione (ram, disco, ecc.), la segmentazione, ecc.

vbuffer è costituito da un campo int per la versione che definisce la struttura successiva

buffer v01 prosegue con un campo long per la lunghezza in bytes (del campo dati), un campo int per il tipo di 
hash/checksum, un campo di lunghezza dipendente dal tipo di hash, un campo int per il tipo di crittografia, 
uno o più campi di lunghezza dipendente dal tipo di crittografia contenente eventuali chiavi o info accessorie, 
infine il campo data

dstruct  è costituito da un campo int per la versione che definisce la struttura successiva

dstruct v01 prosegue  con un campo long per la lunghezza in bytes (del campo struttura), un campo int per il tipo di 
hash/checksum, un campo di lunghezza dipendente dal tipo di hash, un campo int per il tipo di crittografia, 
uno o più campi di lunghezza dipendente dal tipo di crittografia contenente eventuali chiavi o info accessorie, 
infine il campo struttura...in pratica dstruct è un vbuffer con un particolare campo dati (=struttura) fatto così: 
una sequenza di campi che definiscono la struttura...da pensare come, ad es. tipo xml, tipo struct c, ecc.

tipi di dati: 
(elementari, lunghezza fissa)
long
long long
float
double

(elementari, lunghezza variabile)
string (variable size)
void (variable size) (custom and complex type, like image formats, ecc.)

(complessi->lunghezza variabile)
record<type1, type2, ecc.> (ordered, unamed (no field names), not homogeneus)
map<recordtype1, type1> (a multimap is a map with several types as keys)
  a map can accept any possible values as recordkey, or only within a set of recordkeys
  or within any possible combination of sets of fields (es field1:<1,2,3,4,5>, field2:<aa, ab, ac>)
  es. an array of 5 elements is a map with keys as a recordset of int of values 1,2,3,4,5
multimatrix<dims, <size1,..., sizeNdims>, recordtype1> as convenience (map will create too much overhead) is a 
  multidimensional array of record (es. matrix=multimatrix<2,<5,9>,long>)

NB set is implemented as array of void* and not directly supported in vbuffer-dstruct



(containers) (omo-etero, ord-unord, named-unamed, num-of-dimensions, size-of-each-dimension)
es. 
array: omo, ord, unamed, 1-dim, size=num of elements
matrix: omo, ord, unamed, 2-dim, size=m*n (num of rows, cols)
record: etero, ord, named, 1-dim, size=num  of fields
map: omo, ord, unamed, 1-dim, size=undefined/unlimited/irrational (between two elements can fit any element)
set: etero, unord, unamed, 1-dim, size=undef

array/vector<type> (homogeneus)
set (container of any mixed type)
record<type1, type2, ecc.> (ordered and named, not homogeneus)
matrix (multidimensional) is it a particular map (map<int, int, int, ecc.>(typeX))?
map (multidimensional) (map==matrix???)

data element: object containing type (long, float, char*, void), size and stored value (buffer) -> <t,s,b>
record: array (ordered) of de (types are inside each de)
map: 2 arrays, one of recordtype1 or de (keys), one of recordtype2 or de (values), both of same size (must)
multiarray: array of arrays-of-same-size of arrays-of-same-size...etc. of recordtype1 or de
-> any aggregation can be represented by an aggregation of an array (of arrays or de) and its size where 
   any particularity is mapped onto checking the size and type of each array element 
   eg a record is an array of arr/de of any size/type, map is an array of size 2 where 
   elems are type arr each of any same size, matrix is an arr of arr-of-any-same-size of any arr/de of any size/type
-> probably array should be considered a data element as well
