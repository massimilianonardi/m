INPUT OUTPUT

attualmente:
- input ed output sono streams
- input-device (in-dev): rende disponibile l'input proveniente da una determinata classe di devices, standardizzandolo (es. one-value/multi-value -> button/axis, absolute/relative, ecc.)
- input: rende disponibili tutti gli input possibili tramite i vari input-device secondo policy anche molto complesse ed offrendo filtering e remapping molto avanzati
- loader policy deve consentire l'accesso ai vari input-device solo ad input (o a particolari eccezioni)
- le varie ui usano input eventualmente chiedendogli un filtraggio generico dinamico, ma sono loro che devono operare il filtraggio specifico (es. window under mouse coords)
- input event standard:
  id       (string) -> real/virtual device unique identifier
  type     (element) -> globally defined (<=100): keyboard, mouse, audio card, etc. custom defined (>100) internally by specific in-dev
  val_type (element) -> button_down=1, button_up=2, absolute_value=3, relative_value=4, absolute_normalized_value=5, relative_normalized_value=6
  val      (<double>) -> <x1> ... <x1, ... ,xn> (xi: double) (NB key_id is the raw scancode, no lang map, no special keys interpretation...shift, ctrl, etc. are just any key)
- input filter: =in-dev che prende input da altri in-dev rielaborandoli per generare nuovo input (può non poggiare direttamente su alcun device)
  NB un filtro può registrarsi su input, o direttamente sullo specifico in-dev...decidere tramite policy...pensare bene...
  NB nel primo caso loader deve restituire al filtro direttamente il ptr di input perchè deve riconoscere che fanno parte dello stesso processo
  NB es. filtro di tipo mouse+keyb t.c. <x1> può essere l_button_up, vk_A_down, fmode_on, etc. cioè tutti i tasti del mouse e della tastiera sono mappati insieme
  NB es. filtro di tipo mouse t.c. per ogni device con almeno due val continui, vengono presi i primi due assi
  NB es. filtro di tipo keyboard da ogni device di tipo keyboard reinterpreta ogni tasto in base al lang e tasti speciali shift, ctrl, etc.
  NB i filtri come virtual device comportano che ad esempio il translate della keyboard viene fatto una volta sola anche se molti utilizzano il filtro...
  NB un filtro può generare un id fake per simulare uno specifico device...comunque in generale i client non devono guardare l'id, ma alcuni si (es. più mouse -> più puntatori)
  NB i filtri generalmente sono specifici e poco parametrici per massimizzare le performance, 
  ma deve essere implementato anche un filtro generico ultra configurabile che mi permetta una grande vastità di elaborazioni e rimappature (ovviamente un po' lento...)
- i client di input si registrano per determinati eventi sulla base di <id, type, val_type> (compresi eventi virtuali) specificando "-1" per nessun filtro (es. mouse: <-1,mouse,-1>)

--------------------------------------------------------------------------------

- anche un device di i/o come un touchscreen, è in realtà due cose: lcd di output + vetro touch => non esistono device dove in e out siano inscindibili
  quindi: iodev -> driver -> <in, out> / <in> / <out> => ui si interfaccia con in/out non con iodev
- è necessario standardizzare gli i/o (es. tasti keyboard di tutte le lingue; rendering tramite window manager, opengl, o directx;
  output finestre 2D, oggetti e finestre 3D; input 1D, 2D, continuo, discreto, ecc.)

- in-dev -> stream-in-ex (si-ex), input -> stream-in-out-multi (sio-mu)
- in-dev -> stream-in-multi (fast arch = speed ex), input -> stream-in-out-multi (fast arch)
- input acq (fast stream model):
  acq loop (simple, avoid flood, slow for may in-dev): for each in-dev read, if!=empty, dispatch (loop never waits)
  acq loop (multithreaded, synch, slow for few in-dev): for each in-dev instantiation, new dedicated acq thread (while available, read, write in synch to global queue)
  acq loop (no multithreaded, no synch, fastest, no queue man, flood prone): for each in-dev instantiation, call set, write called by in-dev dispatch event based on subscriptions
  l'ultimo acq loop, è quello perfetto, la queue management la può fare un thread separato usando counter per ogni id, set(0) sugli s3m-in flooding, ecc.

comandi di output specifici per alcuni output:
- render_image: può anche essere mappato come suono anche se non è pratico
- render_sound: può anche essere mappato come immagine anche se non è pratico
- render_video: può splittato e mappato su due device diversi (stereo e monitor) o intero (tv)
- render_3D_video: come sopra (3D->2D), o può essere mandato ad un generatore di ologrammi (3D->3D)
NB in generale per l'output andrebbero considerati i 5 sensi umani, poichè essendo l'utente un umano 
   i device out servono proprio per dare feedback all'utente quindi possono essere implementati anche 
   render_taste e render_smell...NB per il tatto c'è già il 3D al quale vanno aggiunte tutte le variabili 
   tattili non grafiche come ad esempio temperatura, umidità, vento, ecc.
NB andrebbero considerate anche pressione, gravità ecc. e qualunque cosa il corpo umano possa percepire...
NB viceversa input mappa i 5 sensi e qualunque cosa nell'universo in text/number
NB i comandi render_text/number/image/sound/video/3D vanno usati solo quando rappresentano i dati per il resto si 
usano le properties cioè si separano i dati dalla presentazione (skin). la differenziazione deriva dal fatto che 
le skin sono date a priori e fanno parte dell'app (anche se se ne possono scaricare altre, ecc.) mentre i 
dati derivano dai srv utilizzati. infatti il compito degli ui_elem è proprio quello di splittare output complessi 
derivanti dai srv e mapparli nei 5 sensi, cioè ui è la mappatura: user_interface = sequence -> human_senses
cioè la ui contestualizza i dati astratti conferendogli una particolare semantica
NB per i text/number va considerato che sono dati astratti che possono essere mappati teoricamente in ognuno dei 
5 sensi, quindi più i dati hanno senso come text/number e meglio è perchè mi lasciano libertà di scelta su 
come rappresentarli, quando invece voglio mappare text/number in uno dei 5 sensi per una migliore percezione 
(come ad es una percentuale in una barra di completamento, istogramma ecc.), questo va contemplato nelle 
properties proprio perchè mantenendo questo disaccoppiamento totale tra dati e presentazione, io comunque ho 
la massima portabilità dell'app su ogni output (a meno dei dati che per loro natura non sono text/number), 
scrivere le app è estremamente semplice e non richiede di scrivere la ui perchè viene automatica dalla 
logica della app e poi possono essere definite varie configurazioni di output che perfezionano l'esperienza 
di interazione (ad es usando audio/video come out, creo una skin multimediale che trasforma una semplice gui 
con solo controlli e bottoni con testo in un'app strabiliante)

NB si potrebbe creare un input filter ui che mappa gli input in:
- execute: esegue il comando correntemente preparato e parametrizzato con le var interne del ui_elem
- select: seleziona il ui_elem
- deselect: deseleziona il ui_elem
- clear_selection:
- invert_selection:
- edit:
- clear:
- save_edit:
- cancel_edit:
- focus:
- highlight:
- create:
- destroy:
- show:
- hide:
- axis_??: coordinata percentuale (definire i valori standard...)
- character_??: "carattere" che può essere ascii, unicode ecc.
- value: numero
NB sono solo un esempio di tutti quelli che mi vengono in mente, le idee più chiare me le posso fare solo poi

NB esempi per ribadire che non si perde in flessibilità o potenzialità:
- un image viewer come xnview che cacha l'immagine successiva e che renderizza progressivamente in 
alta qualità è fattibile così: per la cache renderizzo l'immagine successiva in un controllo 
doppione settato come hidden, poi quando vado avanti swappo la visibilità dei due controlli e 
sull'altro cacho; per la progressiva hq, è analogo in uno ingrandisco fast e sull'altro dopo un timer 
renderizzo hq...NB qui emerge il tema del timing/sincronizzazione/real-time/ecc. che deve essere gestito 
dalla user_interface o dai srv sottostanti? ...pensare!!!
- altro esempio è un player video: posso mandare i frames decodificati dal srv, oppure mando lo stream 
h264 al renderer il quale a sua volta lo manda alla scheda grafica per la decodifica hardware...
anche qui ci sono due controlli (e due output renderer) distinti e qui la logica del disaccoppiamento 
comincia a venire un po' meno perchè la configurazione di decoding nel secondo caso sta nel renderer 
e non nel srv player che ora fa solo da dispacciatore dello stream preso dal file, oppure ancora posso 
fornire al renderer l'id di connessione al srv di storage ed il renderer prende lo stream da solo...
insomma l'accesso alle funzionalità o accelerazioni hardware avanzate creano problemi in questo contesto, 
devo solo assicurarmi di non precludermi la possibilità di utilizzarle pur mantenendo un alto (se non totale) 
disaccoppiamento

NB il concetto di fondo è che ogni cosa può essere un input od un output che di solito vengono utilizzati dai 
vari srv nei loro formati standardizzati...però ogni input/output generico può essere collegato ad una ui a 
patto di avere un opportuno srv di mappatura che converta input/output da/per comandi ui (render, select, 
ecc.)

params sono cose abbastanza fisse, possono anche avere struttura variabile, ma fondamentalmente 
sono "un insieme finito" e mi serve unicamente per configurare il srv e vanno inviati una sola 
volta, mentre l'input è una cosa estremamente variabile, "non prevedibile", continua e potenzialmente 
infinita, cioè uno "stream" e rappresentano concettualmente "dati"...
quindi:
- params: limited-one-time-data, determinano come elaborare l'input ai params non corrisponde un output
- input/output: unlimited-continous-streaming-data, vengono elaborati (secondo i params) per produrre un output
cioè out=f(in) e f=g(params), con f=stream_function e g=point_function

differenza tra funzione e stream-processor è che per le funzioni c'è una corrispondenza sincrona tra 
input ed output, mentre per gli stream io fornisco input asincronamente e poi asincronamente e se 
voglio prendo gli output...NB se serve sincronia per gli stream questa deve essere contemplata 
all'interno dello stream, oppure previsto da timers nello stream processor (con almeno un delay 
tra in e out), ma in ogni caso non c'è la corrispondenza come nella chiamata di funzioni.

lo user input viene tradotto dalla ui in uno input stream di comandi per uno specifico srv.

riflessioni:
- se l'input passato e l'output associato sono scorrelati da tutti gli altri in ed out allora 
il modello da utilizzare è la chiamata di funzione
- se l'input passato è un pezzo di un input più grande e l'output pure viene fornito a pezzi e 
l'out complessivo dipende da tutto l'in complessivo (es. codifica video a doppia passata) allora 
il modello da utilizzare è quello delle streamed read/write indipendenti
- il vero problema è che uno stream processor proprio per sua natura implica un buffering di in ed 
out e quindi la gestione di tali buffer che devono garantire (entro certi limiti) la non perdita 
di pacchetti in o out, il buffering è necessario perchè in una catena di stream processors, il più 
lento non è sempre lo stesso ma è variabile a causa degli input istantanei che possono richiedere 
più o meno potenza di calcolo (NB la velocità di una catena è data dal processore più lento!), 
quindi se non ci fosse buffering tutti i processor starebbero sempre in attesa del più lento, 
mentre col buffering hanno sempre dati da processare...NB il tutto va considerato in "clouding", 
cioè i processors possono stare su pc distribuiti in rete, o sullo stesso pc ma diversi core, ecc.
- io vorrei che il buffering non fosse gestito dallo specifico srv, ma da backends messi prima e 
dopo, ma non sono sicuro sia fattibile...o almeno è facile bufferizzare l'input dall'esterno, 
ma l'output? ...dovrei prevedere un buffer veloce e il processor dovrebbe bloccarsi se c'è un 
pacchetto in out non ancora preso...forse così regge...
- in ogni caso il srv, anche nel caso "funzione", ha al suo interno "molta" sincronizzazione 
(semafori, wait, ecc.) che per sua natura è "pericolosa"...l'alternativa implica la comunicazione 
bidirezionale e quindi un'interfaccia ulteriore che deve implementare il chiamante, oltre al 
puntatore che va passato al srv o al suo stub e gestito da lui in sua vece...tutto ciò implica 
però anche che l'affidabilità del srv dipende anche dal suo chiamante...pessima cosa! ...e poi 
almeno le read andrebbero sincronizzate, per cui mi conviene usare il modello unidirezionale 
sincronizzato e progettare bene la classe base dei srv con tutta la sincronizzazione al suo 
interno...

- stream_in: accetta i pacchetti dello stream in ingresso da processare
- stream_out: ritorna i pacchetti dello stream in uscita processato
